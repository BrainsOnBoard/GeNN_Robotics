#!/usr/bin/python3
# Runs clang-tidy over the bob_robotics repo to find the specified warnings and
# converts the results into a Jenkins-readable XML file. One or more
# compile_commands.json files should be present somewhere in the tree (they
# don't have to be committed to git). These can be generated by CMake by passing
# the argument -DCMAKE_EXPORT_COMPILE_COMMANDS=1.
#
# If the argument --generate-fixes is passed to this script, then it will
# deposit a series of YAML files into ./clang_tidy_fixes. These can then be
# applied like so:
#       clang-apply-replacements ./clang_tidy_fixes
#
# Note that only a small subset of the checks are actually capable of generating
# fixes at present (though most of the modernize-* checks seem to work).

import collections
import itertools
import json
import logging
import multiprocessing as mp
import os
import re
import subprocess
import sys
from xml.sax.saxutils import escape

INCLUDE_CHECKS = (
    'bugprone-*',
    'clang-analyzer-*',
    'concurrency-*',
    'misc-*',
    'modernize-*',
    'openmp-*',
    'performance-*',
)

# Some of these are a bit overzealous...
EXCLUDE_CHECKS = (
    '*osx.*',
    'bugprone-branch-clone',
    'bugprone-exception-escape',
    'bugprone-integer-division',
    'bugprone-narrowing-conversions',
    'clang-analyzer-webkit*',
    'misc-non-private-member-variables-in-classes',
    'modernize-avoid-c-arrays',
    'modernize-concat-nested-namespaces',
    'modernize-pass-by-value',
    'modernize-use-auto',
    'modernize-use-emplace',
    'modernize-use-equals-default',
    'modernize-use-nodiscard',
    'modernize-use-override',
    'modernize-raw-string-literal',
    'modernize-use-trailing-return-type',
    'modernize-return-braced-init-list',
    'openmp-use-default-none',
    'performance-type-promotion-in-math-fn',
)

# Create a `ErrorDescription` tuple with all the information we want to keep.
ErrorDescription = collections.namedtuple(
    'ErrorDescription', 'file line column error error_identifier description')

# This class was adapted from here: https://github.com/PSPDFKit-labs/clang-tidy-to-junit
class ClangTidyConverter:
    # All the errors encountered.
    errors = []

    # Parses the error.
    # Group 1: file path
    # Group 2: line
    # Group 3: column
    # Group 4: error message
    # Group 5: error identifier
    error_regex = re.compile(
        r"^([\w\/\.\-\ ]+):(\d+):(\d+): (.+) (\[[\w\-,\.]+\])$")

    # This identifies the main error line (it has a [the-warning-type] at the end)
    # We only create a new error when we encounter one of those.
    main_error_identifier = re.compile(r'\[[\w\-,\.]+\]$')

    def __init__(self, basename):
        self.basename = basename

    def print_junit_file(self, output_file):
        # Write the header.
        output_file.write("""<?xml version="1.0" encoding="UTF-8" ?>
<testsuites id="1" name="Clang-Tidy" tests="{error_count}" errors="{error_count}" failures="0" time="0">""".format(error_count=len(self.errors)))

        sorted_errors = sorted(self.errors, key=lambda x: x.file)

        # Iterate through the errors, grouped by file.
        for file, errorIterator in itertools.groupby(sorted_errors, key=lambda x: x.file):
            errors = list(errorIterator)
            error_count = len(errors)

            # Each file gets a test-suite
            output_file.write("""\n    <testsuite errors="{error_count}" name="{file}" tests="{error_count}" failures="0" time="0">\n"""
                              .format(error_count=error_count, file=file))
            for error in errors:
                # Write each error as a test case.
                output_file.write("""
        <testcase id="{id}" name="{id}" time="0">
            <failure message="{message}">
{htmldata}
            </failure>
        </testcase>""".format(id="[{}/{}] {}".format(error.line, error.column, error.error_identifier),
                              message=escape(error.error, entities={"\"": "&quot;"}),
                              htmldata=escape(error.description)))
            output_file.write("\n    </testsuite>\n")
        output_file.write("</testsuites>\n")

    def process_error(self, error_array):
        if len(error_array) == 0:
            return

        result = self.error_regex.match(error_array[0])
        if result is None:
            logging.warning(
                'Could not match error_array to regex: %s', error_array)
            return

        # We remove the `basename` from the `file_path` to make prettier filenames in the JUnit file.
        file_path = result.group(1).replace(self.basename, "")
        error = ErrorDescription(file_path, int(result.group(2)), int(
            result.group(3)), result.group(4), result.group(5), "\n".join(error_array[1:]))
        self.errors.append(error)

    def convert(self, input_file, output_file):
        # Collect all lines related to one error.
        current_error = []
        for line in input_file:
            if line == '':
                continue

            # If the line starts with a `/`, it is a line about a file.
            if line[0] == '/':
                # Look if it is the start of a error
                if self.main_error_identifier.search(line, re.M):
                    # If so, process any `current_error` we might have
                    self.process_error(current_error)
                    # Initialize `current_error` with the first line of the error.
                    current_error = [line]
                else:
                    # Otherwise, append the line to the error.
                    current_error.append(line)
            elif len(current_error) > 0:
                # If the line didn't start with a `/` and we have a `current_error`, we simply append
                # the line as additional information.
                current_error.append(line)
            else:
                pass

        # If we still have any current_error after we read all the lines,
        # process it.
        if len(current_error) > 0:
            self.process_error(current_error)

        # Print the junit file.
        self.print_junit_file(output_file)

check_args = None
if INCLUDE_CHECKS or EXCLUDE_CHECKS:
    checks = itertools.chain(INCLUDE_CHECKS, ('-' + check for check in EXCLUDE_CHECKS))
    check_args = '-checks=' + ','.join(checks)

# List the currently enabled checks
args = ['/usr/bin/clang-tidy', '-list-checks']
if check_args:
    args.append(check_args)
subprocess.run(args)

generate_fixes = len(sys.argv) > 1 and sys.argv[1] == '--generate-fixes'
FIXES_DIR = 'clang_tidy_fixes'
if generate_fixes and not os.path.isdir('fixes'):
    os.mkdir(FIXES_DIR)

def run_clang_tidy(file):
    args = ['/usr/bin/clang-tidy', '-p', '.', file]

    # Explicitly (disallow) various checks
    if check_args:
        args.append(check_args)

    # Optionally generate fixes
    if generate_fixes:
        fixes_file = os.path.join(FIXES_DIR, file.replace('/', '_') + '.yaml')
        args.append('--export-fixes=' + fixes_file)

    proc = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout = proc.communicate()[0].decode('utf-8')
    if stdout != '':
        print(stdout)
    return stdout


if __name__ == '__main__':
    all_json = []
    all_files = set()
    exclude_path = os.path.join(os.getcwd(), 'third_party')
    for root, _, files in os.walk('.'):
        # Trim initial ./
        root = root[2:]

        # Don't load the compile_commands.json file from this folder -- that's the output!
        if root == '':
            continue

        # Skip hidden folders
        if any(name != '' and name[0] == '.' for name in root.split('/')):
            continue

        if any(f == 'compile_commands.json' for f in files):
            print('Found compile_commands.json in ' + root)
            with open(os.path.join(root, 'compile_commands.json'), 'r') as file:
                for cmd in json.load(file):
                    # Don't add duplicate files
                    if not cmd['file'].startswith(exclude_path) and not cmd['file'] in all_files:
                        all_json.append(cmd)
                        all_files.add(cmd['file'])

    # Check we found at least one compile_commands.json
    assert len(all_json) > 0
    print()

    # Save concatenated JSON to a combined file
    with open('compile_commands.json', 'w') as file:
        json.dump(all_json, file)

    # Run clang-tidy in parallel over source files and concatenate output
    with mp.Pool() as pool:
        output = ''.join(pool.map(run_clang_tidy, (obj['file'] for obj in all_json))).split('\n')

    # Convert into JUnit-style output file that Jenkins can parse
    converter = ClangTidyConverter(os.getcwd())
    with open('clang_tidy_test_results.xml', 'w') as file:
        converter.convert(output, file)
